{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Trie..., from /usr/local/lib/python2.7/dist-packages/jieba/dict.txt\n",
      "DEBUG:jieba:Building Trie..., from /usr/local/lib/python2.7/dist-packages/jieba/dict.txt\n",
      "loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:loading model from cache /tmp/jieba.cache\n",
      "loading model cost 0.859495162964 seconds.\n",
      "DEBUG:jieba:loading model cost 0.859495162964 seconds.\n",
      "Trie has been built succesfully.\n",
      "DEBUG:jieba:Trie has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import ijson\n",
    "from gensim import corpora, models, similarities\n",
    "import jieba\n",
    "from jieba import analyse\n",
    "jieba.load_userdict(\"new.dict_all\")\n",
    "analyse.load_stop_words('stopword.txt')\n",
    "# .load_stop_words(\"stop_words_list.txt\")\n",
    "f = open(\"../spam-articles-half-a.json\")\n",
    "import itertools\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objects = ijson.items(f, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001*\r\n",
      " + 0.001*ad + 0.000*google + 0.000*─ + 0.000*， + 0.000*_ + 0.000*☆ + 0.000*  + 0.000*/ + 0.000*]\n",
      "0.000*設定 + 0.000*未 + 0.000*內容 + 0.000*  + 0.000*( + 0.000*oacute + 0.000*) + 0.000*nbsp + 0.000*que + 0.000*&\n",
      "0.000*阿福 + 0.000*快打 + 0.000*&# + 0.000*, + 0.000*  + 0.000*! + 0.000*า + 0.000*ร + 0.000*， + 0.000*貝肯\n",
      "0.000*nbsp + 0.000*& + 0.000*; + 0.000*， + 0.000*- + 0.000*! + 0.000*柱筋 + 0.000*  + 0.000*~ + 0.000*/\n",
      "0.003*， + 0.003*  + 0.002*nbsp + 0.002*- + 0.002*& + 0.002*; + 0.002*, + 0.002*。 + 0.001*\r\n",
      " + 0.001*!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "words = []\n",
    "for obj in objects :\n",
    "    if obj['is_spam'] == 0 and obj['content'] != None :\n",
    "        soup = BeautifulSoup(obj['content'])\n",
    "        words.append(list(jieba.cut(soup.getText(),cut_all = False)))\n",
    "        count = count + 1\n",
    "    if count > 100000: break\n",
    "\n",
    "dic = corpora.Dictionary(words)\n",
    "corpus = [dic.doc2bow(text) for text in words]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "lda = models.LdaModel(corpus_tfidf, id2word=dic, num_topics=5)\n",
    "ldaOut=lda.print_topics(5)\n",
    "for topic in ldaOut :\n",
    "    print topic\n",
    "    \n",
    "corpus_lda = lda[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
